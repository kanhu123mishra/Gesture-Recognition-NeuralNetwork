{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7983739,"sourceType":"datasetVersion","datasetId":4699360}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Shree Ganesha","metadata":{"execution":{"iopub.status.busy":"2024-04-03T14:46:19.509718Z","iopub.execute_input":"2024-04-03T14:46:19.510364Z","iopub.status.idle":"2024-04-03T14:46:19.514783Z","shell.execute_reply.started":"2024-04-03T14:46:19.510327Z","shell.execute_reply":"2024-04-03T14:46:19.513719Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Gesture Recognition\nIn this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport datetime\nimport os\nfrom skimage.io import imread\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:59:53.778418Z","iopub.execute_input":"2024-04-02T17:59:53.778896Z","iopub.status.idle":"2024-04-02T17:59:53.783455Z","shell.execute_reply.started":"2024-04-02T17:59:53.778864Z","shell.execute_reply":"2024-04-02T17:59:53.782510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.transform import resize as imresize\nfrom PIL import Image, ImageFilter, ImageEnhance\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:59:54.137603Z","iopub.execute_input":"2024-04-02T17:59:54.138306Z","iopub.status.idle":"2024-04-02T17:59:54.143767Z","shell.execute_reply.started":"2024-04-02T17:59:54.138277Z","shell.execute_reply":"2024-04-02T17:59:54.142900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Ignoring warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:59:46.255745Z","iopub.execute_input":"2024-04-02T17:59:46.256179Z","iopub.status.idle":"2024-04-02T17:59:46.260534Z","shell.execute_reply.started":"2024-04-02T17:59:46.256141Z","shell.execute_reply":"2024-04-02T17:59:46.259590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nnp.random.seed(30)\n\nimport random as rn\nrn.seed(30)\n\nimport tensorflow as tf\ntf.random.set_seed(30)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:59:58.444079Z","iopub.execute_input":"2024-04-02T17:59:58.444789Z","iopub.status.idle":"2024-04-02T17:59:58.511015Z","shell.execute_reply.started":"2024-04-02T17:59:58.444756Z","shell.execute_reply":"2024-04-02T17:59:58.509997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.","metadata":{}},{"cell_type":"code","source":"train_doc = np.random.permutation(open('/kaggle/input/upgrad-gesture-recognistion/Project_data/Project_data/train.csv').readlines())\nval_doc = np.random.permutation(open('/kaggle/input/upgrad-gesture-recognistion/Project_data/Project_data/val.csv').readlines())\n#setting experimental batch size of 20\nbatch_size = 20\n##Setting image dimension =120x120\nxdim, ydim = 120, 120\nimg_idx_sel = range(0,25,2)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:12.621126Z","iopub.execute_input":"2024-04-02T14:23:12.621385Z","iopub.status.idle":"2024-04-02T14:23:12.669356Z","shell.execute_reply.started":"2024-04-02T14:23:12.621363Z","shell.execute_reply":"2024-04-02T14:23:12.668623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator\nThis is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\ndef generator(source_path, folder_list, batch_size, img_idx_sel, xdim, ydim):\n    print('Source path = ', source_path, '; batch size =', batch_size)\n    img_idx = img_idx_sel  # creating a list of image numbers you want to use for a particular video\n    x = len(img_idx)\n    y, z = ydim, xdim  # note the change in order of ydim and xdim\n    while True:\n        t = np.random.permutation(folder_list)\n        num_batches = len(t) // batch_size  # calculate the number of batches based on the total number of folders\n\n        for batch in range(num_batches):  # iterate over the batches\n            batch_data = np.zeros((batch_size, x, y, z, 3))  # initialize batch data\n            batch_labels = np.zeros((batch_size, 5))  # initialize batch labels\n            for folder in range(batch_size):  # iterate over the batch\n                imgs = os.listdir(source_path + '/' + t[folder + (batch * batch_size)].split(';')[0])  # read all the images in the folder\n                for idx, item in enumerate(img_idx):  # Iterate over the frames/images of a folder to read them in\n                    image = imread(source_path + '/' + t[folder + (batch * batch_size)].strip().split(';')[0] + '/' + imgs[item]).astype(np.float32)\n\n                    if image.shape[1] > image.shape[0]:\n                        diff_px = image.shape[1] - image.shape[0]\n                        crop_start = diff_px // 2\n                        crop_end = crop_start + image.shape[0]\n                        image = image[:, crop_start:crop_end]\n                    elif image.shape[0] > image.shape[1]:\n                        diff_px = image.shape[0] - image.shape[1]\n                        crop_start = diff_px // 2\n                        crop_end = crop_start + image.shape[1]\n                        image = image[:, crop_start:crop_end]\n\n                    resized_im = resize(image, (y, z))  # resize the image\n\n                    # normalise and feed in the image\n                    batch_data[folder, idx, :, :, 0] = resized_im[:, :, 0] / 255\n                    batch_data[folder, idx, :, :, 1] = resized_im[:, :, 1] / 255\n                    batch_data[folder, idx, :, :, 2] = resized_im[:, :, 2] / 255\n\n                batch_labels[folder, int(t[folder + (batch * batch_size)].strip().split(';')[2])] = 1\n\n            yield batch_data, batch_labels  # yield the batch data and labels\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:12.670534Z","iopub.execute_input":"2024-04-02T14:23:12.670887Z","iopub.status.idle":"2024-04-02T14:23:12.685594Z","shell.execute_reply.started":"2024-04-02T14:23:12.670847Z","shell.execute_reply":"2024-04-02T14:23:12.684694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!ls /kaggle/input/upgrad-gesture-recognistion/Project_data/Project_data/train","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:22.612939Z","iopub.execute_input":"2024-04-02T14:23:22.613287Z","iopub.status.idle":"2024-04-02T14:23:22.617576Z","shell.execute_reply.started":"2024-04-02T14:23:22.613258Z","shell.execute_reply":"2024-04-02T14:23:22.616461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l /kaggle/working/model_init4_2024-04-02_16_15_17\n!chmod 755 /kaggle/input/upgrad-gesture-recognistion/*\n!cp /kaggle/working/model_init4_2024-04-02_16_15_17/model4-00027-0.44512-0.82206-0.49983-0.81000.keras /kaggle/input/upgrad-gesture-recognistion/\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:51:10.254483Z","iopub.execute_input":"2024-04-03T15:51:10.255784Z","iopub.status.idle":"2024-04-03T15:51:13.554967Z","shell.execute_reply.started":"2024-04-03T15:51:10.255735Z","shell.execute_reply":"2024-04-03T15:51:13.553418Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"total 16172\n-rw-r--r-- 1 root root 1273305 Apr  3 14:45 model4-00001-1.66745-0.39559-2.53384-0.23000.keras\n-rw-r--r-- 1 root root 1273305 Apr  3 14:45 model4-00003-1.08986-0.53235-1.74805-0.20000.keras\n-rw-r--r-- 1 root root 1273305 Apr  3 14:45 model4-00004-1.03704-0.57647-1.55253-0.33000.keras\n-rw-r--r-- 1 root root 1273305 Apr  3 14:45 model4-00005-0.98937-0.60294-1.46682-0.39000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00016-0.49422-0.79412-1.34974-0.47000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00017-0.52767-0.77941-1.22395-0.57000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00018-0.46948-0.80147-0.84139-0.69000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00019-0.50223-0.78824-0.69380-0.74000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00020-0.52646-0.77500-0.61870-0.77000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00021-0.51985-0.78971-0.56018-0.77000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00023-0.44625-0.81618-0.54515-0.78000.keras\n-rw-r--r-- 1 root root 1273306 Apr  3 14:45 model4-00024-0.49305-0.79412-0.51257-0.79000.keras\n-rw-r--r-- 1 root root 1273307 Apr  3 14:45 model4-00027-0.44512-0.82206-0.49983-0.81000.keras\nchmod: changing permissions of '/kaggle/input/upgrad-gesture-recognistion/Neural_Nets_Project_Starter_Code.ipynb': Read-only file system\nchmod: changing permissions of '/kaggle/input/upgrad-gesture-recognistion/Project_data': Read-only file system\ncp: cannot create regular file '/kaggle/input/upgrad-gesture-recognistion/model4-00027-0.44512-0.82206-0.49983-0.81000.keras': Read-only file system\n","output_type":"stream"}]},{"cell_type":"code","source":"curr_dt_time = datetime.datetime.now()\ntrain_path = '/kaggle/input/upgrad-gesture-recognistion/Project_data/Project_data/train'\nval_path = '/kaggle/input/upgrad-gesture-recognistion/Project_data/Project_data/val'\nnum_train_sequences = len(train_doc)\nprint('# training sequences =', num_train_sequences)\nnum_val_sequences = len(val_doc)\nprint('# validation sequences =', num_val_sequences)\nnum_epochs = 20    ### Setting initial 20 epochs to test\nprint ('# epochs =', num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:27.250831Z","iopub.execute_input":"2024-04-02T14:23:27.251207Z","iopub.status.idle":"2024-04-02T14:23:27.257505Z","shell.execute_reply.started":"2024-04-02T14:23:27.251178Z","shell.execute_reply":"2024-04-02T14:23:27.256548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, GRU, Flatten, TimeDistributed, Bidirectional, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, GlobalAveragePooling3D, ConvLSTM2D\nfrom tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras import optimizers\n\n#Input Shape\ninput_shape = (len(img_idx_sel), xdim, ydim, 3)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T14:23:38.933562Z","iopub.execute_input":"2024-04-02T14:23:38.934482Z","iopub.status.idle":"2024-04-02T14:23:38.939702Z","shell.execute_reply.started":"2024-04-02T14:23:38.934449Z","shell.execute_reply":"2024-04-02T14:23:38.938838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Test Model #1","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:12.723317Z","iopub.execute_input":"2024-04-02T14:23:12.723591Z","iopub.status.idle":"2024-04-02T14:23:12.734671Z","shell.execute_reply.started":"2024-04-02T14:23:12.723567Z","shell.execute_reply":"2024-04-02T14:23:12.733690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv3D(64, kernel_size=3, activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling3D(pool_size=2))\nmodel.add(Conv3D(32, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling3D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:23:12.735752Z","iopub.execute_input":"2024-04-02T14:23:12.735996Z","iopub.status.idle":"2024-04-02T14:23:13.480020Z","shell.execute_reply.started":"2024-04-02T14:23:12.735975Z","shell.execute_reply":"2024-04-02T14:23:13.479234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Model summary : Test #1 \",model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.554942Z","iopub.execute_input":"2024-04-01T17:56:15.555251Z","iopub.status.idle":"2024-04-01T17:56:15.578269Z","shell.execute_reply.started":"2024-04-01T17:56:15.555227Z","shell.execute_reply":"2024-04-01T17:56:15.577422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.579336Z","iopub.execute_input":"2024-04-01T17:56:15.579663Z","iopub.status.idle":"2024-04-01T17:56:15.590975Z","shell.execute_reply.started":"2024-04-01T17:56:15.579630Z","shell.execute_reply":"2024-04-01T17:56:15.590223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.592153Z","iopub.execute_input":"2024-04-01T17:56:15.592398Z","iopub.status.idle":"2024-04-01T17:56:15.596348Z","shell.execute_reply.started":"2024-04-01T17:56:15.592376Z","shell.execute_reply":"2024-04-01T17:56:15.595572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n\n# if not os.path.exists(model_name):\n#     os.mkdir(model_name)\n\n# filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\n\n# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n\n# LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1)   # write the REducelronplateau code here\n# callbacks_list = [checkpoint, LR]","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.597475Z","iopub.execute_input":"2024-04-01T17:56:15.597739Z","iopub.status.idle":"2024-04-01T17:56:15.605471Z","shell.execute_reply.started":"2024-04-01T17:56:15.597698Z","shell.execute_reply":"2024-04-01T17:56:15.604583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nmodel_name = 'model_init_' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.606588Z","iopub.execute_input":"2024-04-01T17:56:15.607133Z","iopub.status.idle":"2024-04-01T17:56:15.615674Z","shell.execute_reply.started":"2024-04-01T17:56:15.607101Z","shell.execute_reply":"2024-04-01T17:56:15.614943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:56:15.616633Z","iopub.execute_input":"2024-04-01T17:56:15.616867Z","iopub.status.idle":"2024-04-01T17:56:15.625185Z","shell.execute_reply.started":"2024-04-01T17:56:15.616847Z","shell.execute_reply":"2024-04-01T17:56:15.624341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:57:14.563883Z","iopub.execute_input":"2024-04-01T17:57:14.564268Z","iopub.status.idle":"2024-04-01T17:57:14.575553Z","shell.execute_reply.started":"2024-04-01T17:57:14.564240Z","shell.execute_reply":"2024-04-01T17:57:14.574759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n                        callbacks=callbacks_list, validation_data=val_generator,\n                        validation_steps=validation_steps, class_weight=None, initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:57:17.581250Z","iopub.execute_input":"2024-04-01T17:57:17.581925Z","iopub.status.idle":"2024-04-01T18:23:18.166567Z","shell.execute_reply.started":"2024-04-01T17:57:17.581893Z","shell.execute_reply":"2024-04-01T18:23:18.165760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking GPU details\ngpu_memory_info = tf.config.experimental.get_memory_info(\"GPU:0\")\ngpu_memory_info","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:27:28.631992Z","iopub.execute_input":"2024-04-01T18:27:28.632369Z","iopub.status.idle":"2024-04-01T18:27:28.638639Z","shell.execute_reply.started":"2024-04-01T18:27:28.632340Z","shell.execute_reply":"2024-04-01T18:27:28.637754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:35:41.639872Z","iopub.execute_input":"2024-04-01T18:35:41.640758Z","iopub.status.idle":"2024-04-01T18:35:41.649722Z","shell.execute_reply.started":"2024-04-01T18:35:41.640702Z","shell.execute_reply":"2024-04-01T18:35:41.648854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\nax1 = plt.subplot(121)\nax1 = plt.plot(history.history['loss'])\nax1 = plt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\nax2 = plt.subplot(122)\nax2 = plt.plot(history.history['categorical_accuracy'])\nax2 = plt.plot(history.history['val_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:23:18.859595Z","iopub.execute_input":"2024-04-01T18:23:18.859964Z","iopub.status.idle":"2024-04-01T18:23:19.411142Z","shell.execute_reply.started":"2024-04-01T18:23:18.859938Z","shell.execute_reply":"2024-04-01T18:23:19.410215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:45:34.327881Z","iopub.execute_input":"2024-04-01T18:45:34.328658Z","iopub.status.idle":"2024-04-01T18:45:34.335756Z","shell.execute_reply.started":"2024-04-01T18:45:34.328623Z","shell.execute_reply":"2024-04-01T18:45:34.334406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(history)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:45:50.160137Z","iopub.execute_input":"2024-04-01T18:45:50.160971Z","iopub.status.idle":"2024-04-01T18:45:50.166378Z","shell.execute_reply.started":"2024-04-01T18:45:50.160939Z","shell.execute_reply":"2024-04-01T18:45:50.165471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\n\nmodel2.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\nmodel2.add(Conv3D(64, kernel_size=3, activation='relu'))\nmodel2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n\nmodel2.add(Conv3D(128, kernel_size=3, activation='relu'))\nmodel2.add(MaxPooling3D(pool_size=(1, 2, 2)))\n\nmodel2.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\nmodel2.add(MaxPooling3D(pool_size=(1, 2, 2)))\n\nmodel2.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\nmodel2.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\nmodel2.add(MaxPooling3D(pool_size=(1, 2, 2)))\n\nmodel2.add(Flatten())\nmodel2.add(Dense(512, activation='relu'))\nmodel2.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:25:00.872724Z","iopub.execute_input":"2024-04-02T14:25:00.873690Z","iopub.status.idle":"2024-04-02T14:25:01.017235Z","shell.execute_reply.started":"2024-04-02T14:25:00.873628Z","shell.execute_reply":"2024-04-02T14:25:01.016272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:25:55.905500Z","iopub.execute_input":"2024-04-02T14:25:55.906356Z","iopub.status.idle":"2024-04-02T14:25:55.920401Z","shell.execute_reply.started":"2024-04-02T14:25:55.906323Z","shell.execute_reply":"2024-04-02T14:25:55.919530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)\n##can be skipped if ran fully\n#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nif (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nmodel_name = 'model_init2_' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model2-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:28:27.065876Z","iopub.execute_input":"2024-04-02T14:28:27.066866Z","iopub.status.idle":"2024-04-02T14:28:27.077316Z","shell.execute_reply.started":"2024-04-02T14:28:27.066820Z","shell.execute_reply":"2024-04-02T14:28:27.076432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Model summary : Test #2 \",model2.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:25:11.735611Z","iopub.execute_input":"2024-04-02T15:25:11.736563Z","iopub.status.idle":"2024-04-02T15:25:11.770880Z","shell.execute_reply.started":"2024-04-02T15:25:11.736529Z","shell.execute_reply":"2024-04-02T15:25:11.769960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n\n# Set TensorFlow to use GPU device\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU device 0\n\n# Train the model with GPU\nhistory2 = model2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=40, verbose=1,\n                       callbacks=callbacks_list, validation_data=val_generator,\n                       validation_steps=validation_steps, class_weight=None,\n                       initial_epoch=0, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:28:31.820433Z","iopub.execute_input":"2024-04-02T14:28:31.821162Z","iopub.status.idle":"2024-04-02T15:25:11.379801Z","shell.execute_reply.started":"2024-04-02T14:28:31.821128Z","shell.execute_reply":"2024-04-02T15:25:11.378852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\n\nax1 = plt.subplot(121)\nax1 = plt.plot(history2.history['loss'])\nax1 = plt.plot(history2.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\n\nax2 = plt.subplot(122)\nax2 = plt.plot(history2.history['categorical_accuracy'])\nax2 = plt.plot(history2.history['val_categorical_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:26:31.263899Z","iopub.execute_input":"2024-04-02T15:26:31.264262Z","iopub.status.idle":"2024-04-02T15:26:31.972150Z","shell.execute_reply.started":"2024-04-02T15:26:31.264234Z","shell.execute_reply":"2024-04-02T15:26:31.971064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Model #3","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:26:47.068779Z","iopub.execute_input":"2024-04-02T15:26:47.069150Z","iopub.status.idle":"2024-04-02T15:26:47.073724Z","shell.execute_reply.started":"2024-04-02T15:26:47.069119Z","shell.execute_reply":"2024-04-02T15:26:47.072557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = Sequential()\n\nmodel3.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n\nmodel3.add(Conv3D(64, kernel_size=3, activation='relu'))\nmodel3.add(MaxPooling3D(pool_size=(2, 2, 2)))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.2))\n\nmodel3.add(Conv3D(128, kernel_size=3, activation='relu'))\nmodel3.add(MaxPooling3D(pool_size=(1, 2, 2)))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.2))\n\nmodel3.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\nmodel3.add(MaxPooling3D(pool_size=(1, 2, 2)))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.2))\n\nmodel3.add(GlobalAveragePooling3D())\nmodel3.add(Dense(512, activation='relu'))\nmodel3.add(BatchNormalization())\nmodel3.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:26:48.202167Z","iopub.execute_input":"2024-04-02T15:26:48.202616Z","iopub.status.idle":"2024-04-02T15:26:48.408145Z","shell.execute_reply.started":"2024-04-02T15:26:48.202577Z","shell.execute_reply":"2024-04-02T15:26:48.407164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Model summary : Test #3 \",model3.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:27:08.531753Z","iopub.execute_input":"2024-04-02T15:27:08.532125Z","iopub.status.idle":"2024-04-02T15:27:08.568954Z","shell.execute_reply.started":"2024-04-02T15:27:08.532094Z","shell.execute_reply":"2024-04-02T15:27:08.567923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:29:41.477214Z","iopub.execute_input":"2024-04-02T15:29:41.477954Z","iopub.status.idle":"2024-04-02T15:29:41.486839Z","shell.execute_reply.started":"2024-04-02T15:29:41.477922Z","shell.execute_reply":"2024-04-02T15:29:41.485868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)\n##can be skipped if ran fully\n#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nif (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nmodel_name = 'model_init3_' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model3-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:05:34.167589Z","iopub.execute_input":"2024-04-02T16:05:34.167913Z","iopub.status.idle":"2024-04-02T16:05:34.176973Z","shell.execute_reply.started":"2024-04-02T16:05:34.167888Z","shell.execute_reply":"2024-04-02T16:05:34.176035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n\n# Set TensorFlow to use GPU device\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU device 0\n\n# Train the model with GPU\nhistory3 = model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n                       callbacks=callbacks_list, validation_data=val_generator,\n                       validation_steps=validation_steps, class_weight=None,\n                       initial_epoch=0, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:30:35.756510Z","iopub.execute_input":"2024-04-02T15:30:35.756890Z","iopub.status.idle":"2024-04-02T16:05:34.165807Z","shell.execute_reply.started":"2024-04-02T15:30:35.756863Z","shell.execute_reply":"2024-04-02T16:05:34.164944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\n\nax1 = plt.subplot(121)\nax1 = plt.plot(history3.history['loss'])\nax1 = plt.plot(history3.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\n\nax2 = plt.subplot(122)\nax2 = plt.plot(history3.history['categorical_accuracy'])\nax2 = plt.plot(history3.history['val_categorical_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:06:29.709178Z","iopub.execute_input":"2024-04-02T16:06:29.709838Z","iopub.status.idle":"2024-04-02T16:06:30.285724Z","shell.execute_reply.started":"2024-04-02T16:06:29.709803Z","shell.execute_reply":"2024-04-02T16:06:30.284750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model #4 with GRU","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:10:02.116188Z","iopub.execute_input":"2024-04-02T16:10:02.116836Z","iopub.status.idle":"2024-04-02T16:10:02.121030Z","shell.execute_reply.started":"2024-04-02T16:10:02.116799Z","shell.execute_reply":"2024-04-02T16:10:02.120010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model4 = Sequential()\n\n#Adding another TimeDistributed MaxPooling2D layer (32)\nmodel4.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=input_shape))\nmodel4.add(TimeDistributed(MaxPooling2D((2,2))))\nmodel4.add(BatchNormalization())\nmodel4.add(Dropout(0.2))\n\n#Adding another TimeDistributed MaxPooling2D layer (64)\nmodel4.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\nmodel4.add(TimeDistributed(MaxPooling2D((2,2))))\nmodel4.add(BatchNormalization())\nmodel4.add(Dropout(0.2))\n\n#Adding another TimeDistributed GlobalAveragePooling2D layer (64)\nmodel4.add(TimeDistributed(GlobalAveragePooling2D()))\nmodel4.add(TimeDistributed(Dense(64, activation='relu')))\nmodel4.add(BatchNormalization())\nmodel4.add(Dropout(0.2))\n\n##Adding GRU Layer (128) with BatchNormalization\nmodel4.add(GRU(128))\nmodel4.add(BatchNormalization())\nmodel4.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:13:45.929235Z","iopub.execute_input":"2024-04-02T16:13:45.929941Z","iopub.status.idle":"2024-04-02T16:13:46.278041Z","shell.execute_reply.started":"2024-04-02T16:13:45.929908Z","shell.execute_reply":"2024-04-02T16:13:46.277064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Model summary : Test #4 \",model4.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:05:15.492841Z","iopub.execute_input":"2024-04-02T17:05:15.493735Z","iopub.status.idle":"2024-04-02T17:05:15.522536Z","shell.execute_reply.started":"2024-04-02T17:05:15.493696Z","shell.execute_reply":"2024-04-02T17:05:15.521694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:14:24.665781Z","iopub.execute_input":"2024-04-02T16:14:24.666154Z","iopub.status.idle":"2024-04-02T16:14:24.675346Z","shell.execute_reply.started":"2024-04-02T16:14:24.666123Z","shell.execute_reply":"2024-04-02T16:14:24.674409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)\n##can be skipped if ran fully\n#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nif (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nmodel_name = 'model_init4_' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model4-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:15:17.422683Z","iopub.execute_input":"2024-04-02T16:15:17.423513Z","iopub.status.idle":"2024-04-02T16:15:17.432463Z","shell.execute_reply.started":"2024-04-02T16:15:17.423476Z","shell.execute_reply":"2024-04-02T16:15:17.431518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n\n# Set TensorFlow to use GPU device\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU device 0\n\n# Train the model with GPU\nhistory4 = model4.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=30, verbose=1,\n                       callbacks=callbacks_list, validation_data=val_generator,\n                       validation_steps=validation_steps, class_weight=None,\n                       initial_epoch=0, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:15:42.758718Z","iopub.execute_input":"2024-04-02T16:15:42.759361Z","iopub.status.idle":"2024-04-02T16:56:05.140752Z","shell.execute_reply.started":"2024-04-02T16:15:42.759330Z","shell.execute_reply":"2024-04-02T16:56:05.139890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,6))\n\nax1 = plt.subplot(121)\nax1 = plt.plot(history4.history['loss'])\nax1 = plt.plot(history4.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\n\nax2 = plt.subplot(122)\nax2 = plt.plot(history4.history['categorical_accuracy'])\nax2 = plt.plot(history4.history['val_categorical_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:58:04.419441Z","iopub.execute_input":"2024-04-02T16:58:04.420323Z","iopub.status.idle":"2024-04-02T16:58:04.988757Z","shell.execute_reply.started":"2024-04-02T16:58:04.420286Z","shell.execute_reply":"2024-04-02T16:58:04.987823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history4.history.keys())\nprint(history4.history['loss'][-1])\nprint(history4.history['categorical_accuracy'][-1])\nprint(history4.history['val_categorical_accuracy'][-1])\nprint(history4.history['val_loss'][-1])\nprint(history4.history['learning_rate'][-1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:55:37.953283Z","iopub.execute_input":"2024-04-02T17:55:37.953937Z","iopub.status.idle":"2024-04-02T17:55:37.960233Z","shell.execute_reply.started":"2024-04-02T17:55:37.953905Z","shell.execute_reply":"2024-04-02T17:55:37.959260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model #5 with LTSM","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:04:57.332117Z","iopub.execute_input":"2024-04-02T17:04:57.332982Z","iopub.status.idle":"2024-04-02T17:04:57.336645Z","shell.execute_reply.started":"2024-04-02T17:04:57.332949Z","shell.execute_reply":"2024-04-02T17:04:57.335697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5 = Sequential()\n\nmodel5.add(TimeDistributed(Conv2D(8, (3,3), activation='relu'), input_shape=input_shape))\n\nmodel5.add(BatchNormalization())\nmodel5.add(TimeDistributed(Conv2D(16, (3,3), activation='relu')))\n\nmodel5.add(BatchNormalization())\nmodel5.add(ConvLSTM2D(8, kernel_size = 3, return_sequences=False))\n\n#Adding BatchNormalization & TimeDistributed relu actived Dense Layer (64)\nmodel5.add(BatchNormalization())\nmodel5.add(TimeDistributed(Dense(64, activation='relu')))\n\n#Adding BatchNormalization & GlobalAveragePooling2D\nmodel5.add(BatchNormalization())\nmodel5.add(GlobalAveragePooling2D())\n\n#Adding Dense Layer - relu (64)\nmodel5.add(Dense(64, activation='relu'))\n\n#Adding Dense Layer - softmax (5)\nmodel5.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:05:41.741162Z","iopub.execute_input":"2024-04-02T17:05:41.741525Z","iopub.status.idle":"2024-04-02T17:05:41.885587Z","shell.execute_reply.started":"2024-04-02T17:05:41.741495Z","shell.execute_reply":"2024-04-02T17:05:41.884822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Model summary : Test #5 \",model5.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:05:49.748616Z","iopub.execute_input":"2024-04-02T17:05:49.749319Z","iopub.status.idle":"2024-04-02T17:05:49.777520Z","shell.execute_reply.started":"2024-04-02T17:05:49.749287Z","shell.execute_reply":"2024-04-02T17:05:49.776631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nmodel5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:06:08.589977Z","iopub.execute_input":"2024-04-02T17:06:08.590349Z","iopub.status.idle":"2024-04-02T17:06:08.599030Z","shell.execute_reply.started":"2024-04-02T17:06:08.590319Z","shell.execute_reply":"2024-04-02T17:06:08.598112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)\n##can be skipped if ran fully\n#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nif (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nmodel_name = 'model_init5_' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model5-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:06:30.297964Z","iopub.execute_input":"2024-04-02T17:06:30.298845Z","iopub.status.idle":"2024-04-02T17:06:30.307761Z","shell.execute_reply.started":"2024-04-02T17:06:30.298797Z","shell.execute_reply":"2024-04-02T17:06:30.306810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set TensorFlow to use GPU device\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU device 0\n\n# Train the model with GPU\nhistory5 = model5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=30, verbose=1,\n                       callbacks=callbacks_list, validation_data=val_generator,\n                       validation_steps=validation_steps, class_weight=None,\n                       initial_epoch=0, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:07:22.672097Z","iopub.execute_input":"2024-04-02T17:07:22.672475Z","iopub.status.idle":"2024-04-02T17:47:54.023407Z","shell.execute_reply.started":"2024-04-02T17:07:22.672444Z","shell.execute_reply":"2024-04-02T17:47:54.022568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,6))\n\nax1 = plt.subplot(121)\nax1 = plt.plot(history5.history['loss'])\nax1 = plt.plot(history5.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\n\nax2 = plt.subplot(122)\nax2 = plt.plot(history5.history['categorical_accuracy'])\nax2 = plt.plot(history5.history['val_categorical_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:51:37.455740Z","iopub.execute_input":"2024-04-02T17:51:37.456739Z","iopub.status.idle":"2024-04-02T17:51:38.047140Z","shell.execute_reply.started":"2024-04-02T17:51:37.456704Z","shell.execute_reply":"2024-04-02T17:51:38.046239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### The best model is Model #4 for the below 2 reasons :\n    ### i) The difference between Training & Validation loss is the least\n    ### ii) Model accuracy is the best out of all other models","metadata":{"execution":{"iopub.status.busy":"2024-04-03T14:51:27.802087Z","iopub.execute_input":"2024-04-03T14:51:27.803347Z","iopub.status.idle":"2024-04-03T14:51:27.808483Z","shell.execute_reply.started":"2024-04-03T14:51:27.803289Z","shell.execute_reply":"2024-04-03T14:51:27.807198Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"###Re-training model #4 / best model with tunned parameters to see if there is any performance improvement or not.","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:01:04.042824Z","iopub.execute_input":"2024-04-02T18:01:04.043173Z","iopub.status.idle":"2024-04-02T18:01:04.049530Z","shell.execute_reply.started":"2024-04-02T18:01:04.043147Z","shell.execute_reply":"2024-04-02T18:01:04.048580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, TimeDistributed, GlobalAveragePooling2D, Dense, GRU\n\nbest_model = Sequential()\n\n# Adding a TimeDistributed Convolutional layer with 64filters\nbest_model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu'), input_shape=input_shape))\n# Adding a TimeDistributed MaxPooling2D layer\nbest_model.add(TimeDistributed(MaxPooling2D((2, 2))))\nbest_model.add(BatchNormalization())\nbest_model.add(Dropout(0.25))\n\n# Adding another TimeDistributed Convolutional layer with 128filters\nbest_model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n# Adding another TimeDistributed MaxPooling2D layer\nbest_model.add(TimeDistributed(MaxPooling2D((2, 2))))\nbest_model.add(BatchNormalization())\nbest_model.add(Dropout(0.25))\n\n\n# Adding a TimeDistributed GlobalAveragePooling2D\nbest_model.add(TimeDistributed(GlobalAveragePooling2D()))\nbest_model.add(TimeDistributed(Dense(128, activation='relu')))\nbest_model.add(BatchNormalization())\nbest_model.add(Dropout(0.25))\n\n\n\n# Adding a GRU layer with 256 units\nbest_model.add(GRU(256))\nbest_model.add(BatchNormalization())\nbest_model.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:03:55.189027Z","iopub.execute_input":"2024-04-02T18:03:55.189395Z","iopub.status.idle":"2024-04-02T18:03:55.804619Z","shell.execute_reply.started":"2024-04-02T18:03:55.189364Z","shell.execute_reply":"2024-04-02T18:03:55.803871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.01)\nbest_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:05:56.379432Z","iopub.execute_input":"2024-04-02T18:05:56.379824Z","iopub.status.idle":"2024-04-02T18:05:56.393504Z","shell.execute_reply.started":"2024-04-02T18:05:56.379792Z","shell.execute_reply":"2024-04-02T18:05:56.392756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size,img_idx_sel, xdim, ydim)\nval_generator = generator(val_path, val_doc, batch_size,img_idx_sel, xdim, ydim)\n##can be skipped if ran fully\n#####\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom datetime import datetime\n\nif (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nmodel_name = 'best_model' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S') + '/'\nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'best_model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:06:39.670845Z","iopub.execute_input":"2024-04-02T18:06:39.671592Z","iopub.status.idle":"2024-04-02T18:06:39.681217Z","shell.execute_reply.started":"2024-04-02T18:06:39.671559Z","shell.execute_reply":"2024-04-02T18:06:39.680112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set TensorFlow to use GPU device\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU device 0\n\n# Train the model with GPU\nbest_model_history = best_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=35, verbose=1,\n                       callbacks=callbacks_list, validation_data=val_generator,\n                       validation_steps=validation_steps, class_weight=None,\n                       initial_epoch=0, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:07:58.893443Z","iopub.execute_input":"2024-04-02T18:07:58.893837Z","iopub.status.idle":"2024-04-02T18:55:09.001720Z","shell.execute_reply.started":"2024-04-02T18:07:58.893805Z","shell.execute_reply":"2024-04-02T18:55:09.000704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,6))\n\nax1 = plt.subplot(121)\nax1 = plt.plot(best_model_history.history['loss'])\nax1 = plt.plot(best_model_history.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower left')\n\nax2 = plt.subplot(122)\nax2 = plt.plot(best_model_history.history['categorical_accuracy'])\nax2 = plt.plot(best_model_history.history['val_categorical_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:55:09.003737Z","iopub.execute_input":"2024-04-02T18:55:09.004002Z","iopub.status.idle":"2024-04-02T18:55:09.637290Z","shell.execute_reply.started":"2024-04-02T18:55:09.003978Z","shell.execute_reply":"2024-04-02T18:55:09.636321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### The tweaked model is having lower accuracy than model4","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:58:56.126431Z","iopub.execute_input":"2024-04-02T18:58:56.127163Z","iopub.status.idle":"2024-04-02T18:58:56.131002Z","shell.execute_reply.started":"2024-04-02T18:58:56.127129Z","shell.execute_reply":"2024-04-02T18:58:56.130062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history4.history.keys())\nprint(history4.history['loss'][-1])\nprint(history4.history['categorical_accuracy'][-1])\nprint(history4.history['val_categorical_accuracy'][-1])\nprint(history4.history['val_loss'][-1])\nprint(history4.history['learning_rate'][-1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:58:04.100703Z","iopub.execute_input":"2024-04-02T18:58:04.101639Z","iopub.status.idle":"2024-04-02T18:58:04.107814Z","shell.execute_reply.started":"2024-04-02T18:58:04.101605Z","shell.execute_reply":"2024-04-02T18:58:04.106871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(best_model_history.history.keys())\nprint(best_model_history.history['loss'][-1])\nprint(best_model_history.history['categorical_accuracy'][-1])\nprint(best_model_history.history['val_categorical_accuracy'][-1])\nprint(best_model_history.history['val_loss'][-1])\nprint(best_model_history.history['learning_rate'][-1])","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:58:23.320347Z","iopub.execute_input":"2024-04-02T18:58:23.320710Z","iopub.status.idle":"2024-04-02T18:58:23.327116Z","shell.execute_reply.started":"2024-04-02T18:58:23.320680Z","shell.execute_reply":"2024-04-02T18:58:23.326215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The best model is Model #4 for the below 2 reasons :\n  #### i)  The difference between Training & Validation loss is the least.\n  #### ii) Model accuracy is the best out of all other models.","metadata":{"execution":{"iopub.status.busy":"2024-04-03T14:51:55.562181Z","iopub.execute_input":"2024-04-03T14:51:55.562619Z","iopub.status.idle":"2024-04-03T14:51:55.568505Z","shell.execute_reply.started":"2024-04-03T14:51:55.562585Z","shell.execute_reply":"2024-04-03T14:51:55.567106Z"}}},{"cell_type":"markdown","source":"## Please use model4 for test result validation as the tweaked model(best_model) is having marginally lesser accuracy than model4","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:59:37.621115Z","iopub.execute_input":"2024-04-02T18:59:37.621479Z","iopub.status.idle":"2024-04-02T18:59:37.625716Z","shell.execute_reply.started":"2024-04-02T18:59:37.621447Z","shell.execute_reply":"2024-04-02T18:59:37.624751Z"}}},{"cell_type":"markdown","source":"# Thank you ","metadata":{}}]}